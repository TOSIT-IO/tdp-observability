# Copyright 2022 TOSIT.IO
# SPDX-License-Identifier: Apache-2.0

---
#######################################################################
# TEMPORARY                                                           #
# Remove after the vars are tracked in tdp_vars_defaults/tdp_cluster  #
#######################################################################

# Cluster name
cluster_name: mycluster

#######################################################################
# TEMPORARY                                                           #
# Remove after the vars are tracked in tdp_vars_defaults/tdp_cluster  #
#######################################################################

tdp_observability_root_dir: "{{ tdp_root_dir }}"
# Grafana ports
grafana_web_port: 3000

# Prometheus ports
prometheus_web_port: 9090

# Prometheus basicAuth
prometheus_admin_user: admin
prometheus_admin_password: PrometheusAdmin123

# Alertmanager basicAuth
alertmanager_admin_user: admin
alertmanager_admin_password: AlertAdmin123


# Promtail ports
promtail_web_port: 9080
promtail_grpc_port: 9095

# Loki ports
loki_web_port: 3100
loki_grpc_port: 9096

# Node Exporter port
exporter_node_http_port: 9100

#################################
# Service & Component logs dirs #
#################################
node_exporter_log_dir: /var/log/node-exporter
node_exporter_log_file: node-exporter.log

grafana_log_dir: /var/log/grafana
grafana_log_file: "grafana.log"     # do not change. Grafana forces this filename. Variable is here only for promtail

promtail_log_dir: /var/log/promtail
promtail_log_file: promtail.log

loki_log_dir: /var/log/loki
loki_log_file: loki.log

prometheus_log_dir: /var/log/prometheus
prometheus_log_file: prometheus.log

alertmanager_log_dir: /var/log/alertmanager
alertmanager_log_file: alertmanager.log

observability_common_labels: {}
#  cluster: "{{ cluster_name }}"

#
# observability_tdp_targets structure :
# service_name
#    +--- component_name
#              +---- group : name of the ansible group that runs this component.
#              |             Optional : should be specified only if not equal
#              |             to '{{ service_name }}_{{ component_name }}'
#              +---- jobs  : list of scrape jobs to configure
#
# each job has the following entries :
# - exporter_port              : exporter service port - for prometheus job
# - log_file                   : log file path - for promtail job
# - name_suffix                : mandatory if more than one job :
#                                job_name in prometheus or promtail scrapes will be
#                                equal to '{{ service }}_{{ component }}_{{ suffix }}
# - prometheus_scrape_options  : options passed to prometheus scrape
#                                cf. https://prometheus.io/docs/prometheus/latest/configuration/configuration
# - promtail_pipeline          : can be either a pipeline dictionary as specified in
#                                cf. https://grafana.com/docs/loki/latest/send-data/promtail/pipelines
#                                or a string, key to a predefined pipeline from the "promtail_pipelines" dictionary
#                                defined in "tdp_vars_default/loki/loki_promtail.yml"
#                                default pipeline is promtail_pipelines['default']
#
# Additionaly :
# - labels can be applied to scrapes and defined at any level of the configuration tree
# - enabled: jobs can be disabled by setting 'enabled' key to false.
#
# example:
# service:
#   component:
#     jobs:
#       - log_file: /var/log/foo/foo.log
#         promtail_pipeline:
#           - multiline:
#               firstline: '^\d{4}-\d{2}-\d{2}[T]\d{2}:\d{2}:\d{2}'
#       - exporter_port: 8888
#         prometheus_scrape_options:
#           scrape_interval: 10s
#           scheme: https
#           tls_config:
#             ca_file: "{{ ca_file }}"
#
dashboard_with_workers: "service02/service-components-and-workers"
dashboard_without_workers: "service01/service-components"
dashboard_python: "service03/python-process"

observability_tdp_targets:
  hbase:
    labels:
      type: tdp_core
      svc_dashboard: "{{ dashboard_with_workers }}"
    master:
      jobs:
        - exporter_port: "{{ exporter_hbase_hm_http_port }}"
          log_file: "{{ hbase_log_dir }}/{{ hbase_hm_log_file }}"
        - name_suffix: audit
          log_file: "{{ hbase_log_dir }}/{{ hbase_master_ranger_audit_file }}"
          labels:
            type: tdp_audit
          promtail_pipeline: json_audit
          enabled: "{{ enable_ranger_audit_log4j | default(false) }}"

    region_server:
      group: hbase_rs
      labels: { 'worker': 'True' }
      jobs:
        - exporter_port: "{{ exporter_hbase_hrs_http_port }}"
          log_file: "{{ hbase_log_dir }}/{{ hbase_hrs_log_file }}"
        - name_suffix: audit
          log_file: "{{ hbase_log_dir }}/{{ hbase_rs_ranger_audit_file }}"
          labels:
            type: tdp_audit
          promtail_pipeline: json_audit
          enabled: "{{ enable_ranger_audit_log4j | default(false) }}"


    rest:
      jobs:
        - exporter_port: "{{ exporter_hbase_hr_http_port }}"
          log_file: "{{ hbase_log_dir }}/{{ hbase_hr_log_file }}"
    phoenix_queryserver_daemon:
      group: phoenix_queryserver_daemon
      jobs:
        - exporter_port: "{{ exporter_hbase_pqs_http_port }}"
          log_file: "{{ phoenix_log_dir }}/{{ phoenix_queryserver_log_file }}"
  hdfs:
    labels:
      type: tdp_core
      svc_dashboard: "{{ dashboard_with_workers }}"
    datanode:
      group: hdfs_dn
      labels: { 'worker': 'True' }
      jobs:
        - exporter_port: "{{ exporter_hdfs_dn_http_port }}"
          log_file: "{{ hdfs_log_dir }}/{{ hadoop_hdfs_datanode_log_file }}"
    journal_node:
      group: hdfs_jn
      jobs:
        - exporter_port: "{{ exporter_hdfs_jn_http_port }}"
          log_file: "{{ hdfs_log_dir }}/{{ hadoop_hdfs_journalnode_log_file }}"
    namenode:
      group: hdfs_nn
      jobs:
        - exporter_port: "{{ exporter_hdfs_nn_http_port }}"
          logfile: "{{ hdfs_log_dir }}/{{ hadoop_hdfs_namenode_log_file }}"
        - name_suffix: zkfc
          exporter_port: "{{ exporter_hdfs_zkfc_http_port }}"
          log_file: "{{ hdfs_log_dir }}/{{ hadoop_hdfs_zkfc_log_file }}"
        - name_suffix: audit
          log_file: "{{ hdfs_log_dir }}/{{ hadoop_hdfs_ranger_audit_file }}"
          labels:
            type: tdp_audit
          promtail_pipeline: json_audit
          enabled: "{{ enable_ranger_audit_log4j | default(false) }}"

    httpfs:
      jobs:
        - log_file: "{{ hdfs_log_dir }}/{{ hadoop_hdfs_httpfs_log_file }}"
          exporter_port: "{{ exporter_hdfs_httpfs_http_port }}"
  hive:
    labels:
      type: tdp_core
      svc_dashboard: "{{ dashboard_without_workers }}"
    metastore:
      group: hive_ms
      jobs:
        - exporter_port: "{{ exporter_hive_hms_http_port }}"
          log_file: "{{ hive_log_dir }}/{{ hive_ms_log_file }}"
    server2s:
      group: hive_s2
      jobs:
        - exporter_port: "{{ exporter_hive_hs2_http_port }}"
          log_file: "{{ hive_log_dir }}/{{ hive_s2_log_file }}"
        - name_suffix: audit
          log_file: "{{ hive_log_dir }}/{{ hive_ranger_audit_file }}"
          labels:
            type: tdp_audit
          promtail_pipeline: json_audit
          enabled: "{{ enable_ranger_audit_log4j | default(false) }}"

  knox:
    labels:
      type: tdp_core
      svc_dashboard: "{{ dashboard_without_workers }}"
    gateway:
      group: knox
      jobs:
        - exporter_port: "{{ exporter_knox_gateway_http_port }}"
          log_file: "{{ knox_log_dir }}/{{ knox_gateway_log_file }}"
        - name_suffix: audit
          log_file: "{{ knox_log_dir }}/{{ knox_ranger_audit_file }}"
          labels:
            type: tdp_audit
          promtail_pipeline: json_audit
          enabled: "{{ enable_ranger_audit_log4j | default(false) }}"

  ranger:
    labels:
      type: tdp_core
      svc_dashboard: "{{ dashboard_without_workers }}"
    admin:
      jobs:
        - exporter_port: "{{ exporter_ranger_ra_http_port }}"
          log_file: "{{ ranger_log_dir }}/{{ ranger_admin_log_file }}"
    usersync:
      jobs:
        - exporter_port: "{{ exporter_ranger_ru_http_port }}"
          log_file: "{{ ranger_log_dir }}/{{ ranger_usersync_log_file }}"
    key_management_service:
      group: ranger_kms
      jobs:
        - exporter_port: "{{ exporter_ranger_kms_http_port }}"
          log_file: "{{ ranger_kms_log_dir }}/{{ ranger_kms_log_file }}"
    solr:
      jobs:
        - log_file: "{{ ranger_log_dir }}/{{ ranger_solr_log_file }}"
  spark2:
    labels:
      type: tdp_core
      svc_dashboard: "{{ dashboard_without_workers }}"
    history_server:
      group: spark_hs
      jobs:
        - log_file: "{{ spark2_log_dir }}/{{ spark2_hs_log_file }}"
          exporter_port: "{{ exporter_spark_hs_http_port }}"
  spark3:
    labels:
      type: tdp_core
      svc_dashboard: "{{ dashboard_without_workers }}"
    history_server:
      group: spark3_hs
      jobs:
        - log_file: "{{ spark3_log_dir }}/{{ spark3_hs_log_file }}"
          exporter_port: "{{ exporter_spark3_hs_http_port }}"
  yarn:
    labels:
      type: tdp_core
      svc_dashboard: "{{ dashboard_with_workers }}"
    ressource_manager:
      group: yarn_rm
      jobs:
        - exporter_port: "{{ exporter_yarn_rm_http_port }}"
          log_file: "{{ yarn_log_dir }}/{{ hadoop_yarn_resourcemanager_log_file }}"
        - name_suffix: audit
          log_file: "{{ yarn_log_dir }}/{{ hadoop_yarn_ranger_audit_file }}"
          labels:
            type: tdp_audit
          promtail_pipeline: json_audit
          enabled: "{{ enable_ranger_audit_log4j | default(false) }}"

    mapred_history_server:
      group: mapred_jhs
      jobs:
        - exporter_port: "{{ exporter_mapred_jhs_http_port }}"
          log_file: "{{ mapred_log_dir }}/{{ hadoop_mapred_historyserver_log_file }}"
    node_manager:
      labels: { 'worker': 'True' }
      group: yarn_nm
      jobs:
        - exporter_port: "{{ exporter_yarn_nm_http_port }}"
          log_file: "{{ yarn_log_dir }}/{{ hadoop_yarn_nodemanager_log_file }}"
    timeline_server:
      group: yarn_ats
      jobs:
        - exporter_port: "{{ exporter_yarn_ats_http_port }}"
          log_file: "{{ yarn_log_dir }}/{{ hadoop_yarn_timelineserver_log_file }}"
  zookeeper:
    labels:
      type: tdp_core
      svc_dashboard: "{{ dashboard_without_workers }}"
    server:
      group: zk
      jobs:
        - exporter_port: "{{ exporter_zookeeper_server_http_port }}"
          log_file: "{{ zookeeper_log_dir }}/{{ zookeeper_log_file }}"
        - name_suffix: trace
          log_file: "{{ zookeeper_log_dir }}/{{ zookeeper_tracelog_file }}"
  #
  # Observability
  #
  grafana:
    labels:
      type: tdp_observability
    server:
      group: grafana
      jobs:
        - log_file: "{{ grafana_log_dir }}/{{ grafana_log_file }}"
          promtail_pipeline:
            - logfmt:
                mapping:
                  datetime: t
                  level:
            - timestamp:
                format: 'RFC3339'
                source: 'datetime'
            - labels:
                level: ''
  exporter:
    node:
      jobs:
        - exporter_port: "{{ exporter_node_http_port }}"
          labels:
            type: tdp_infra
        - log_file: "{{ node_exporter_log_dir }}/{{ node_exporter_log_file }}"
          promtail_pipeline: observability
          labels:
            type: tdp_observability
  prometheus:
    server:
      group: prometheus
      jobs:
        - log_file: "{{ prometheus_log_dir }}/{{ prometheus_log_file }}"
          promtail_pipeline: observability
          labels:
            type: tdp_observability
  loki:
    server:
      group: loki
      jobs:
        - log_file: "{{ loki_log_dir }}/{{ loki_log_file }}"
          promtail_pipeline: observability
          labels:
            type: tdp_observability
    promtail:
      group: promtail
      jobs:
        - log_file: "{{ promtail_log_dir }}/{{ promtail_log_file }}"
          promtail_pipeline: observability
          labels:
            type: tdp_observability
